%%%%%%%% ICML 2019 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

\usepackage{kotex}
% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{multirow}

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2019} with \usepackage[nohyperref]{icml2019} above.
\usepackage{hyperref}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
%\usepackage{icml2019}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2019}

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{COSE474-2019F: Final Project Report}

\begin{document}
	
	\twocolumn[
	\icmltitle{COSE474-2019F: Final Project Report \\
		Improving Detecting DeepFake Videos with Fake Real Dataset}
	
	% It is OKAY to include author information, even for blind
	% submissions: the style file will automatically remove it for you
	% unless you've provided the [accepted] option to the icml2019
	% package.
	
	% List of affiliations: The first argument should be a (short)
	% identifier you will use later to specify author affiliations
	% Academic affiliations should list Department, University, City, Region, Country
	% Industry affiliations should list Company, City, Region, Country
	
	% You can specify symbols, otherwise they are numbered in order.
	% Ideally, you should not use this facility. Affiliations will be numbered
	% in order of appearance and this is the preferred way.
	\icmlsetsymbol{equal}{*}
	
	\begin{icmlauthorlist}
		\icmlauthor{제한재}{}
		\icmlauthor{허환}{}
		\icmlauthor{홍주연}{}
		\icmlauthor{도재형}{}
		\icmlauthor{채병주}{}
	\end{icmlauthorlist}
	
	%\icmlaffiliation{ku}{Department of Computer Science \& Engineering, Korea University, Seoul, Korea}
	
	
	%\icmlcorrespondingauthor{the}{myemail@korea.ac.kr}
	%\icmlcorrespondingauthor{Eee Pppp}{ep@eden.co.uk}
	
	% You may provide any keywords that you
	% find helpful for describing your paper; these are used to populate
	% the "keywords" metadata in the PDF but will not be shown in the document
	\icmlkeywords{Machine Learning, ICML}
	
	\vskip 0.3in
	]
	
	% this must go after the closing bracket ] following \twocolumn[ ...
	
	% This command actually creates the footnote in the first column
	% listing the affiliations and the copyright notice.
	% The command takes one argument, which is text to display at the start of the footnote.
	% The \icmlEqualContribution command is standard text for equal contribution.
	% Remove it (just {}) if you do not need this facility.
	
	%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
	%\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.
	
	\begin{abstract}
		이번 프로젝트에서는 input video가 real video인지 생성된 DeepFake video인지를 detect하는 model을 구현하고, 이 model의 성능을 향상시키기 위한 다양한 방법에 대해 탐구하였다. FaceForensics++ 및 Google에서 공개한 DeepFake Detection Dataset을 사용하였으며, \textbf{내용 추가바람}
	\end{abstract}
	
	\section{Introduction}
	% Motivation & Problem definition
	DeepFake는 GAN과 같은 deep neural network를 사용하여 사람의 얼굴을 합성하는 기술이다. 일상적인 사진들로도 쉽고 빠르게 자연스러운 결과물을 생성할 수 있다. 하지만, DeepFake 기술의 발전과 social media 상에서 많은 data를 구할 수 있게 되면서 타인을 사칭하는 계정과 DeepFake pornography의 양산으로 사회적으로 큰 문제가 되고 있다.
	
	이러한 문제들로 인해 최근 DeepFake detection에 대한 연구의 필요성이 대두되면서, DeepFake detection은 현재 computer vision 분야의 주요 issue 중 하나가 되었다. 이에 Google에서는 DeepFake detection 연구를 위한 dataset을 공개하였고 \cite{googleblog}, Facebook에서도 DeepFake detection challenge를 dataset 공개과 함께 진행할 예정임을 알렸다 \cite{facebookblog}.
	
	따라서 이번 프로젝트에서는 주어진 image가 DeepFake image인지 아닌지를 판단하는 DeepFake detection model을 개발하고, 그 성능을 평가해 보고자 한다.
	
	\section{Project Environment}
	
	우리는 처음에는 Google Colab을 사용하여 프로젝트를 진행하였다. 하지만 대용량의 video dataset을 다운로드하는 과정에서 Google Colab은 코드 실행 후 12시간 후에 자동으로 종료하는 문제가 있었기 때문에, Google Colab 대신 GPU 서버를 대여하여 프로젝트를 진행하였다. GPU 서버에서는 Anaconda를 통해 Python 환경설정을 하고, Jupyter Notebook을 웹으로 접속하여 작업하는 방식으로 진행하였다.
	
	\section{Team Members}
	% Student id, name, role
	우리 팀은 제한재 (2014210110), 허환 (2015410124), 홍주연 (2015410041), 도재형 (2016320210), 채병주 (2016320168) 의 5명으로 구성되어 있다.
	모든 팀원이 모델 기획 및 구현에 참여하였다. 추가로, 기타 여러 가지 업무를 다음과 같이 분담하여 진행하기로 하였다.
	
	\section{Related Works}
	
	여기에 SOTA 입력
	
		\subsection{DeepFake Datasets}
		% FaceForensics, google DFD
		DeepFake detection model의 학습을 위한 다양한 dataset들이 공개되어 있다. R\"ossler el al.은 fake video detection을 위한 FaceForensics++ dataset을 공개했다 \cite{roessler2019faceforensicspp}. 이 dataset은 DeepFakes 외에도 FaceSwap, NeuralTextures 등과 같은 다양한 방식의 video manipulation을 통해 만든 fake video들과, YouTube에 업로드 된 real video들을 모아 둔 dataset이다. 또, Google에서는 DeepFake Detection Dataset \cite{DDD_GoogleJigSaw2019} 을 공개하였는데, 이 dataset은 방대한 양의 DeepFake video data들을 포함하고 있다. 이 dataset 역시 FaceForensics++의 GitHub 
		repository에 함께 공개되어 있다.
		
		\subsection{Normal Image and Video Classifier}
		% Xception, ECO
		
		\subsection{DeepFake Video Detection Models}
		% Mesonet, Eye blinking
	
	\section{Architecture and Implementation or Something}
	% Baseline
	% Algorithm
	
	\subsection{Implementation}
	
	
	
	\section{Main Challenges}
	% TODO
	
	
	\section{Conclusion}
	% Comparison with SOTA
	테이블 인용 시 Table~\ref{conclusion} 과 같이 사용하면 됩니다.
	
	\begin{table}[t]
		\caption{여기에 텍스트 입력. Dataset 이름 앞의 \textsc{R}, \textsc{F}는 각각 real 혹은 fake video들의 dataset을 의미한다.}
		\label{conclusion}
		\vskip 0.15in
		\begin{center}
			\begin{small}
				\begin{sc}
					\begin{tabular}{lrrrr}
						\toprule
						\multirow{2}{*}{Datasets}	&	\multicolumn{4}{c}{Models}		\\
						&	AAA	&	BBB	&	CCC	&	R-C3D	\\
						\midrule
						R-Actors		&	15.0	&	15.0	&	15.0	&	89.1	\\
						R-YouTube		&	15.0	&	15.0	&	15.0	&	75.5	\\
						F-DeepFakes		&	15.0	&	15.0	&	15.0	&	94.4	\\
						F-Face2Face		&	15.0	&	15.0	&	15.0	&	86.6	\\
						F-FaceSwap		&	15.0	&	15.0	&	15.0	&	90.4	\\
						F-NeuralTextures &	15.0	&	15.0	&	15.0	&	87.6	\\
						\bottomrule
					\end{tabular}
				\end{sc}
			\end{small}
		\end{center}
		\vskip -0.1in
	\end{table}
	
	\section{Future Work}
	% TODO
	
	% In the unusual situation where you want a paper to appear in the
	% references without citing it in the main text, use \nocite
	
	
	\bibliography{report}
	\bibliographystyle{icml2019}
	
	
\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019. Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
