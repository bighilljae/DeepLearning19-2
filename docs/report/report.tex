%%%%%%%% ICML 2019 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

\usepackage{kotex}
% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2019} with \usepackage[nohyperref]{icml2019} above.
\usepackage{hyperref}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
%\usepackage{icml2019}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2019}

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{COSE474-2019F: Final Project Report}

\begin{document}
	
	\twocolumn[
	\icmltitle{COSE474-2019F: Final Project Report \\
		Improving Detecting DeepFake Videos with Fake Real Dataset}
	
	% It is OKAY to include author information, even for blind
	% submissions: the style file will automatically remove it for you
	% unless you've provided the [accepted] option to the icml2019
	% package.
	
	% List of affiliations: The first argument should be a (short)
	% identifier you will use later to specify author affiliations
	% Academic affiliations should list Department, University, City, Region, Country
	% Industry affiliations should list Company, City, Region, Country
	
	% You can specify symbols, otherwise they are numbered in order.
	% Ideally, you should not use this facility. Affiliations will be numbered
	% in order of appearance and this is the preferred way.
	\icmlsetsymbol{equal}{*}
	
	\begin{icmlauthorlist}
		\icmlauthor{제한재}{}
		\icmlauthor{허환}{}
		\icmlauthor{홍주연}{}
		\icmlauthor{도재형}{}
		\icmlauthor{채병주}{}
	\end{icmlauthorlist}
	
	%\icmlaffiliation{ku}{Department of Computer Science \& Engineering, Korea University, Seoul, Korea}
	
	
	%\icmlcorrespondingauthor{the}{myemail@korea.ac.kr}
	%\icmlcorrespondingauthor{Eee Pppp}{ep@eden.co.uk}
	
	% You may provide any keywords that you
	% find helpful for describing your paper; these are used to populate
	% the "keywords" metadata in the PDF but will not be shown in the document
	\icmlkeywords{Machine Learning, ICML}
	
	\vskip 0.3in
	]
	
	% this must go after the closing bracket ] following \twocolumn[ ...
	
	% This command actually creates the footnote in the first column
	% listing the affiliations and the copyright notice.
	% The command takes one argument, which is text to display at the start of the footnote.
	% The \icmlEqualContribution command is standard text for equal contribution.
	% Remove it (just {}) if you do not need this facility.
	
	%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
	%\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.
	
	\begin{abstract}
		이 프로젝트는 주어진 input video가 original video인지 딥러닝 모델로 생성된 manipulated DeepFake video (이하 DeepFake)인지 detect하는 model을 구현하고, 이 model의 성능을 향상시키기 위한 다양한 방법에 대해 탐구하였다. FaceForensics++ 및 Google에서 DeepFake 생성용으로 촬영한 영상과 youtube 영상을 original 영상으로 채택하고 DeepFake, Face2Face, FaceSwap, NeuralTextures 방식으로 생성한 영상과 전용 DeepFakeDetection을 dataset으로 사용하였다.
	\end{abstract}
	
	\section{Introduction}
	% Motivation & Problem definition
	DeepFake는 GAN과 같은 deep neural network를 사용하여 사람의 얼굴을 합성하는 기술이다. 일상적인 사진들로도 쉽고 빠르게 자연스러운 결과물을 생성할 수 있고, 심지어 동영상으로 촬영된 영상도 자연스럽게 합성한다. 하지만, DeepFake 기술의 발전과 social media 상에서 많은 data를 구할 수 있게 되면서 타인을 사칭하는 계정과 FakeVideo로 기업의 Security를 위협하거나 DeepFake pornography등 사람이 쉽게 판별하기 어렵다는 점을 악용하는 경우 사회적으로 큰 문제가 되고 있다.
	
	이러한 문제들로 인해 DeepFake detection에 대한 연구의 필요성이 대두되었고, DeepFake detection은 현재 computer vision 분야의 주요 issue 중 하나가 되었다. 이에 Google에서는 DeepFake detection 연구를 위한 dataset을 공개하였고 \cite{googleblog}, Facebook에서도 DeepFake detection challenge를 dataset 공개과 함께 진행할 예정임을 알렸다 \cite{facebookblog}.
	
	따라서 이 프로젝트는 주어진 image/video가 DeepFake 를 이용해 합성되었는지 아닌지를 판단하는 DeepFake detection model을 개발하고, 그 성능을 평가해 보고자 한다.
	
	\section{Project Environment}
	
	처음 진행할때에는 Google Colab의 자원을 사용하여 프로젝트를 진행하였다. 하지만 대용량의 video dataset을 다운로드하는 과정에서 Colab의 유효 세션 길이가 12시간으로 한정되어 있어서 다른 환경의 필요성이 요구되었다. 이 프로젝트에서는 Google Colab 대신 GPU 서버를 호스팅하여 프로젝트를 진행하였다. GPU 서버에서는 Anaconda를 통해 Python 환경설정을 하고, Jupyter Notebook을 웹으로 접속하여 작업하는 방식으로 Colab에서 진행하던 방식을 유지하며 진행하였다.
	
	\section{Team Members}
	% Student id, name, role
	프로젝트의 모든 팀원이 모델 기획 및 구현에 참여하였다. \newline 
	제한재 (2014210110) -- Data preprocessing, Hosting Server Management\newline
	허환 (2015410124), 채병주 (2016320168) -- Model fine-tuning\newline
	홍주연 (2015410041), 도재형 (2016320210) -- SOTA model \& dataset research 
	\section{Related Works}
	
	현재 FaceForensics++ 에서 제시하고 있는 SOTA라고 볼 수 있는 연구는 \cite{darius2018MesoNet}과 Xception이 있다.
	
		\subsection{DeepFake Datasets}
		% FaceForensics, google DFD
		DeepFake detection model의 학습을 위한 다양한 dataset들이 공개되어 있다. R\"ossler el al.은 fake video detection을 위한 FaceForensics++ dataset을 공개했다 \cite{roessler2019faceforensicspp}. 이 dataset은 DeepFakes 외에도 FaceSwap, NeuralTextures 등과 같은 다양한 방식의 video manipulation을 통해 만든 fake video들과, YouTube에 업로드 된 real video들을 모아 둔 dataset이다. 또, Google에서는 DeepFake Detection Dataset \cite{DDD_GoogleJigSaw2019} 을 공개하였는데, 이 dataset은 방대한 양의 DeepFake video data들을 포함하고 있다. 이 dataset 역시 FaceForensics++의 GitHub 
		repository에 함께 공개되어 있다.
		
		\subsection{Normal Image and Video Classifier}
		% Xception, ECO
		
		\subsection{DeepFake Video Detection Models}
		% Mesonet, Eye blinking
	
	\section{Architecture and Implementation or Something}
	% Baseline
	% Algorithm
	
	\subsection{Implementation}
	
	
	
	\section{Main Challenges}
	% TODO
	
	
	\section{Conclusion}
	% Comparison with SOTA
	
	\section{Future Work}
	% TODO
	
	% In the unusual situation where you want a paper to appear in the
	% references without citing it in the main text, use \nocite
	
	
	\bibliography{report}
	\bibliographystyle{icml2019}
	
	
\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019. Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
